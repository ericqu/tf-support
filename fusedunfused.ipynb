{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fusedunfused",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNCTQLnvTq2i9kq1va9HZ+1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericqu/tf-support/blob/master/fusedunfused.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Icg-T6bZ2rWQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "bb302ca0-ebbc-4277-b56f-cbbec958a1a6"
      },
      "source": [
        "#for issue 40510\n",
        "!pip install tf-nightly\n",
        "!pip install tensorflow-model-optimization\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-nightly in /usr/local/lib/python3.6/dist-packages (2.3.0.dev20200618)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.18.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.34.2)\n",
            "Requirement already satisfied: tb-nightly<2.4.0a0,>=2.3.0a0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.3.0a20200618)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.4.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.3.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.29.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.2.1)\n",
            "Requirement already satisfied: tf-estimator-nightly in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.3.0.dev2020061901)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (47.3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.2.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (4.1.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (4.6)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2020.4.5.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-model-optimization in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (0.1.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.12.0)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaU1zjRF_dyo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "dd82e65a-7c41-4568-86e1-091838628f51"
      },
      "source": [
        "import gc\n",
        "import sys\n",
        "from datetime import date, datetime, time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sci\n",
        "import scipy.io as sio\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras.layers import (GRU, LSTM, Activation, Dense, Input,\n",
        "                                     SimpleRNN)\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "sns.set()\n",
        "print(sys.version)\n",
        "print(\"Tensor Flow:\",  tf.__version__)\n",
        "print(\"Keras: \", keras.__version__)\n",
        "print(\"Numpy: \", np.__version__)\n",
        "print(\"Seaborn: \", sns.__version__)\n",
        "print(\"scipy: \", sci.__version__)\n",
        "\n",
        "\n",
        "def increment_and_get(counter_path=\"counter.txt\", increment=True):\n",
        "    import os\n",
        "    value = 0\n",
        "    if os.path.exists(counter_path):\n",
        "        f = open(counter_path, \"r\")\n",
        "        value = int(f.readline())\n",
        "        f.close()\n",
        "        if increment is True:\n",
        "            value = value + 1\n",
        "    else:\n",
        "        if increment is True:\n",
        "            value = 1\n",
        "        else:\n",
        "            value = 0\n",
        "\n",
        "    if increment is True:\n",
        "        f = open(counter_path, \"w\")\n",
        "        f.write(str(value))\n",
        "        f.close()\n",
        "\n",
        "    return value\n",
        "\n",
        "\n",
        "model_iteration = increment_and_get(increment=False)\n",
        "\n",
        "\n",
        "def get_files_desc(path=\"nodefault\", cases=[0, 1, 2, 3, 4, 5, 6, 7]):\n",
        "    Cases_description = [\"Baseline\", \"Noise addition\", \"Adding respiratory noise\", \"helixoidal movements added \",\n",
        "                         \"alternatively changing periods\",\n",
        "                         \"contraction with noise\",\n",
        "                         \"ex beats\", \"TP\"\n",
        "                         ]\n",
        "\n",
        "    each_paths, each_descriptions = list(), list()\n",
        "    for i in cases:\n",
        "        full_path = path + str(i+1) + \".mat\"\n",
        "        each_paths.append(full_path)\n",
        "        description = Cases_description[i]\n",
        "        each_descriptions.append(description)\n",
        "    return each_paths, each_descriptions\n",
        "\n",
        "\n",
        "# cfg_cases_list = [2, 3, 4, 5]\n",
        "cfg_cases_list = [1]\n",
        "cfg_usable_cases_list = range(len(cfg_cases_list))\n",
        "print (\"Usable Cases list:\", *cfg_usable_cases_list)\n",
        "\n",
        "\n",
        "# cfg_EL_list = [5, 6, 7, 10, 11, 12, 15, 16, 17, 20, 21, 22, 25, 26, 27, 30, 31, 32 ] # Electrodes we are going to use\n",
        "cfg_EL_list = range(3,34,50) # Electrodes we are going to use (from, to, step)\n",
        "cfg_usable_EL_list = range(len(cfg_cases_list)) \n",
        "print (\"Electrodes list:\", *cfg_EL_list)\n",
        "\n",
        "file_paths, Cases_descriptions = get_files_desc(\n",
        "    \"fecgsyn_c\", cfg_cases_list)\n",
        "print(\"file_paths:\", file_paths)\n",
        "print(\"Cases_descriptions\", Cases_descriptions)\n",
        "\n",
        "# configuration variables\n",
        "cfg_mixture_gain = 100.0 \n",
        "cfg_mo_gain = 100.0  \n",
        "cfg_fo_gain = 10.0   \n",
        "cfg_in_len_seq = 250  # 350, 250, 150\n",
        "cfg_out_len_seq = 50\n",
        "cfg_batches_size = 500 # 5000 is too high - 4000 works at about same speed as 3000 ; 50 is 10 times slower than3000\n",
        "cfg_epochs = 1\n",
        "cfg_obs_ps = 500  # hertz\n",
        "cfg_storage_type_f = np.float16\n",
        "\n",
        "models = list()\n",
        "models.append(dict(name=\"baseline_\" + str(model_iteration), nb_neurons=20,\n",
        "                   files=file_paths, per_file_description=Cases_descriptions, electrode_list= cfg_EL_list))\n",
        "\n",
        "tf.random.set_seed(12345)\n",
        "print(\"Model iteration: \", model_iteration)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.6.9 (default, Apr 18 2020, 01:56:04) \n",
            "[GCC 8.4.0]\n",
            "Tensor Flow: 2.3.0-dev20200618\n",
            "Keras:  2.4.0\n",
            "Numpy:  1.18.5\n",
            "Seaborn:  0.10.1\n",
            "scipy:  1.4.1\n",
            "Usable Cases list: 0\n",
            "Electrodes list: 3\n",
            "file_paths: ['fecgsyn_c2.mat']\n",
            "Cases_descriptions ['Noise addition']\n",
            "Model iteration:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAidOokiAJ0t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "331a3d23-d30f-460c-8bda-4ed7f7b1b3f7"
      },
      "source": [
        "def load_mat(path):\n",
        "    c_mat = sio.loadmat(path, variable_names=['out'])\n",
        "    mat_out_data = c_mat['out']\n",
        "    mat_out_type = mat_out_data.dtype\n",
        "    c_data = {n: mat_out_data[n][0, 0] for n in mat_out_type.names}\n",
        "    print(\"loading\", path, \" columns: \", str(\n",
        "        [n for n, v in c_data.items()]), \" EL, observations: \", c_data[\"mecg\"].shape)\n",
        "\n",
        "    mecg = np.array((c_data['mecg'] / cfg_mo_gain), dtype=cfg_storage_type_f)\n",
        "\n",
        "    fecg1 = np.array(c_data[\"fecg\"][0][0] / cfg_fo_gain, dtype=cfg_storage_type_f)\n",
        "    fecg2 = np.zeros(fecg1.shape, dtype=np.float32)\n",
        "    fecg3 = np.zeros(fecg1.shape, dtype=np.float32)\n",
        "    fecg4 = np.zeros(fecg1.shape, dtype=np.float32)\n",
        "\n",
        "    mixture = np.array(c_data[\"mixture\"] / cfg_mixture_gain, dtype=cfg_storage_type_f)\n",
        "\n",
        "    # we have indexes, all is zero but the indexes\n",
        "    mqrs_i = np.array(c_data[\"mqrs\"], np.int64)\n",
        "    mqrs = np.zeros(fecg1.shape[1], dtype=np.int8) # not per electrodes\n",
        "    mqrs[mqrs_i] = 1;\n",
        "\n",
        "    fqrs_i = np.array(c_data[\"fqrs\"][0][0] , np.int64)\n",
        "    fqrs = np.zeros(fecg1.shape[1], dtype=np.int8) # not per electrodes\n",
        "    fqrs[fqrs_i] = 1;\n",
        "\n",
        "    return mecg, fecg1, fecg2, fecg3, fecg4, mixture, mqrs, fqrs\n",
        "\n",
        "all_mecg, all_fecg1, all_fecg2, all_fecg3, all_fecg4, all_mixture , all_mqrs , all_fqrs  = list(),list(), list(), list(), list(), list(), list(), list()\n",
        "\n",
        "for c_path in file_paths:\n",
        "    c_mecg, c_fecg1, c_fecg2, c_fecg3, c_fecg4, c_mixture, c_mqrs, c_fqrs = load_mat(c_path)\n",
        "    print(\"completed.\")\n",
        "\n",
        "    all_mecg.append(c_mecg)\n",
        "    all_fecg1.append(c_fecg1)\n",
        "    all_fecg2.append(c_fecg2)\n",
        "    all_fecg3.append(c_fecg3)\n",
        "    all_fecg4.append(c_fecg4)\n",
        "    all_mixture.append(c_mixture)\n",
        "    all_mqrs.append(c_mqrs)\n",
        "    all_fqrs.append(c_fqrs)\n",
        "\n",
        "all_mecg = np.array(all_mecg)\n",
        "all_fecg1 = np.array(all_fecg1)\n",
        "all_fecg2 = np.array(all_fecg2)\n",
        "all_fecg3 = np.array(all_fecg3)\n",
        "all_fecg4 = np.array(all_fecg4)\n",
        "all_mixture = np.array(all_mixture)\n",
        "all_mqrs = np.array(all_mqrs)\n",
        "all_fqrs = np.array(all_fqrs)\n",
        "\n",
        "\n",
        "print(\"Total obs (all_mixture.shape):\", all_mixture.shape)\n",
        "print(\"Total obs (all_fqrs.shape):\", all_fqrs.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading fecgsyn_c2.mat  columns:  ['mecg', 'mixture', 'mqrs', 'fqrs', 'fecg']  EL, observations:  (34, 20000)\n",
            "completed.\n",
            "Total obs (all_mixture.shape): (1, 34, 20000)\n",
            "Total obs (all_fqrs.shape): (1, 20000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urRVwWMdAkjS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "79957efe-cb84-4e23-b335-811752019db8"
      },
      "source": [
        "def prep_electrodes_array(x, ym, yf, yqm, yqf, l_seq, o_seq, els, cases):\n",
        "    gen_types = [\"original\", \"no_fo\", \"no_signal\"]\n",
        "    \n",
        "    X, YM, YF1, YQM, YQF1 = None, None, None, None, None\n",
        "    for case in cases:\n",
        "        for el in els:\n",
        "            for gen_type in gen_types:\n",
        "                if X is None:  # First time\n",
        "                    X, YM, YF1, YQM, YQF1= prep_training_array(x[case, el], ym[case,el], yf[case,el], yqm[case], yqf[case], l_seq, o_seq, gen_type)\n",
        "                else:\n",
        "                    X_t, YM_t, YF1_t, YQM_t, YQF1_t = prep_training_array(x[case, el], ym[case,el], yf[case,el], yqm[case], yqf[case], l_seq, o_seq, gen_type)\n",
        "                    X = np.concatenate((X, X_t))\n",
        "                    YM = np.concatenate((YM, YM_t))\n",
        "                    YF1 = np.concatenate((YF1, YF1_t))\n",
        "                    YQM = np.concatenate((YQM, YQM_t))\n",
        "                    YQF1 = np.concatenate((YQF1, YQF1_t))\n",
        "\n",
        "    return X, YM, YF1, YQM, YQF1\n",
        "\n",
        "\n",
        "def prep_training_array(x, ym, yf, yqm, yqf, l_seq, o_seq, gen_type=\"original\"):\n",
        "    if (len(x) != len(ym)):\n",
        "        raise NameError(\"x and y have different lengths \" +\n",
        "                        len(x) + \" \" + len(ym) + \" cannot continue.\")\n",
        "\n",
        "    X = np.empty([len(x)-l_seq, l_seq, 1], dtype=cfg_storage_type_f)\n",
        "    YM = np.empty([len(x)-l_seq, o_seq, 1], dtype=cfg_storage_type_f)\n",
        "    YF1 = np.empty([len(x)-l_seq, o_seq, 1], dtype=cfg_storage_type_f)\n",
        "    YQM = np.empty([len(x)-l_seq, o_seq, 1], dtype=np.int8)\n",
        "    YQF1 = np.empty([len(x)-l_seq, o_seq, 1], dtype=np.int8)\n",
        "\n",
        "    step = 1\n",
        "    \n",
        "    for i in range(0, len(x)-(l_seq), step):\n",
        "        X[i] = x[i:i + l_seq].reshape(l_seq, 1)\n",
        "        YM[i] = ym[i + l_seq - o_seq: i + l_seq].reshape(o_seq, 1)\n",
        "        YF1[i] = yf[i + l_seq - o_seq: i + l_seq].reshape(o_seq, 1)\n",
        "        YQM[i] = yqm[i + l_seq - o_seq: i + l_seq].reshape(o_seq, 1)\n",
        "        YQF1[i] = yqf[i + l_seq - o_seq: i + l_seq].reshape(o_seq, 1)\n",
        "\n",
        "    return X, YM, YF1, YQM, YQF1\n",
        "\n",
        "\n",
        "print(\"Data Preparation started\")\n",
        "print(\"training data\")\n",
        "X_train, Y_trainM, Y_trainF1 , Y_trainQM, Y_trainQF1 = prep_electrodes_array(\n",
        "    all_mixture, all_mecg, all_fecg1, all_mqrs, all_fqrs, cfg_in_len_seq , cfg_out_len_seq, cfg_EL_list, cfg_usable_cases_list)\n",
        "print(\"test data\")\n",
        "\n",
        "X_test, Y_testM, Y_testF1, Y_testQM, Y_testQF1 = prep_training_array(\n",
        "    all_mixture[0,8], all_mecg[0,8], all_fecg1[0,8], all_mqrs[0], all_fqrs[0], cfg_in_len_seq, cfg_out_len_seq)\n",
        "\n",
        "print(\"shuffling\")\n",
        "together = np.hstack((X_train, Y_trainM, Y_trainF1 , Y_trainQM, Y_trainQF1))\n",
        "np.random.shuffle(together)\n",
        "X_train, Y_trainM, Y_trainF1, Y_trainQM, Y_trainQF1 = np.hsplit(together, [cfg_in_len_seq,\n",
        "                                                                           cfg_in_len_seq+cfg_out_len_seq,\n",
        "                                                                           cfg_in_len_seq+cfg_out_len_seq *2,\n",
        "                                                                           cfg_in_len_seq+cfg_out_len_seq *3,])\n",
        "def debug_display(name , val):\n",
        "    print(\"debug:\", name,  val.shape, val.dtype , \"min :\", np.min(val), \"max:\", np.max(val))\n",
        "\n",
        "debug_display(\"X_train\", X_train)\n",
        "debug_display(\"Y_trainM\", Y_trainM)\n",
        "debug_display(\"Y_trainF1\", Y_trainF1)\n",
        "debug_display(\"Y_trainQM\", Y_trainQM)\n",
        "debug_display(\"Y_trainQF1\", Y_trainQF1)\n",
        "\n",
        "debug_display(\"X_test\", X_test)\n",
        "debug_display(\"Y_testM\", Y_testM)\n",
        "debug_display(\"Y_testF1\", Y_testF1)\n",
        "debug_display(\"Y_testQM\", Y_testQM)\n",
        "debug_display(\"Y_testQF1\", Y_testQF1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Preparation started\n",
            "training data\n",
            "test data\n",
            "shuffling\n",
            "debug: X_train (59250, 250, 1) float16 min : -123.56 max: 257.5\n",
            "debug: Y_trainM (59250, 50, 1) float16 min : -87.5 max: 212.8\n",
            "debug: Y_trainF1 (59250, 50, 1) float16 min : -147.4 max: 144.1\n",
            "debug: Y_trainQM (59250, 50, 1) float16 min : 0.0 max: 1.0\n",
            "debug: Y_trainQF1 (59250, 50, 1) float16 min : 0.0 max: 1.0\n",
            "debug: X_test (19750, 250, 1) float16 min : -90.2 max: 177.5\n",
            "debug: Y_testM (19750, 50, 1) float16 min : -47.25 max: 140.1\n",
            "debug: Y_testF1 (19750, 50, 1) float16 min : -119.5 max: 431.5\n",
            "debug: Y_testQM (19750, 50, 1) int8 min : 0 max: 1\n",
            "debug: Y_testQF1 (19750, 50, 1) int8 min : 0 max: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEENJs2SBKW0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f521575b-156d-48dd-9027-4c5339a171eb"
      },
      "source": [
        "print(gc.collect())\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7iwK8cyBQjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "fdc78c26-9013-42b8-8529-995718bc02f5"
      },
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import metrics\n",
        "\n",
        "\n",
        "def define_model(length_of_sequences, batch_size=None, modelName=\"nonamegiven\"):\n",
        "    inp = Input(batch_shape=(batch_size, length_of_sequences, 1), name=\"inputs\")\n",
        "    # lstmM = Bidirectional(LSTM(50, name=\"lstm_m\", return_sequences=True))(inp)\n",
        "    lstmM = LSTM(50, name=\"lstm_m\", return_sequences=True)(inp)\n",
        "    flat = Flatten()(lstmM)\n",
        "    denseM = Dense(50, kernel_regularizer=regularizers.l2(0.0001))(flat)\n",
        "    reshapeM = Reshape((50, 1))(denseM)\n",
        "    denseM = TimeDistributed(\n",
        "        Dense(1, kernel_regularizer=regularizers.l2(\n",
        "            0.0001), bias_initializer='zeros'),\n",
        "        input_shape=(50, 1))(reshapeM)\n",
        "    out_M = Reshape((50, 1), name=\"om\")(denseM)\n",
        "    model = Model(inputs=[inp], outputs=[out_M], name=modelName)\n",
        "    model.compile(\n",
        "        loss={\"om\": \"mean_squared_error\"},\n",
        "        optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "        metrics=['mae'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "for m in models:\n",
        "    m[\"k_model\"] = define_model(\n",
        "        length_of_sequences=cfg_in_len_seq, modelName=m[\"name\"])\n",
        "    m[\"k_model\"].summary()\n",
        "    \n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"baseline_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          [(None, 250, 1)]          0         \n",
            "_________________________________________________________________\n",
            "lstm_m (LSTM)                (None, 250, 50)           10400     \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 12500)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 50)                625050    \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 50, 1)             0         \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 50, 1)             2         \n",
            "_________________________________________________________________\n",
            "om (Reshape)                 (None, 50, 1)             0         \n",
            "=================================================================\n",
            "Total params: 635,452\n",
            "Trainable params: 635,452\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YobjSjncBrqW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e822cd0b-894b-402c-d00d-0e4ce8ff3304"
      },
      "source": [
        "# Training\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, min_delta=5, restore_best_weights= True)\n",
        "\n",
        "for m in models:\n",
        "    print (\"fitting\")\n",
        "    m[\"k_history\"] = m[\"k_model\"].fit(x=X_train, y=[Y_trainM, Y_trainF1], \n",
        "                                      batch_size=cfg_batches_size, epochs=cfg_epochs, verbose=1, validation_split=0.1, \n",
        "                                      callbacks=[early_stop])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fitting\n",
            "107/107 [==============================] - 77s 716ms/step - loss: 462.5976 - mae: 8.8712 - val_loss: 297.5235 - val_mae: 7.7927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9trLgeSf3_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c5b20b49-72d1-4168-d07b-ed026c0760c3"
      },
      "source": [
        "run_model = tf.function(lambda x: m[\"k_model\"](x))\n",
        "# This is important, let's fix the input size.\n",
        "BATCH_SIZE = cfg_batches_size\n",
        "STEPS = 250\n",
        "INPUT_SIZE = 1\n",
        "concrete_func = run_model.get_concrete_function(\n",
        "    tf.TensorSpec([BATCH_SIZE, STEPS, INPUT_SIZE], m[\"k_model\"].inputs[0].dtype))\n",
        "\n",
        "MODEL_DIR = \"support40510\"\n",
        "m[\"k_model\"].save(MODEL_DIR, save_format=\"tf\", signatures=concrete_func)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "tflite_model_file = 'current_float_support_model.tflite'\n",
        "f = open(tflite_model_file, 'wb')\n",
        "f.write(tflite_model)\n",
        "f.close()\n",
        "print(\"no quantization (support) version TFLite conversion saved\")\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: support40510/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: support40510/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "no quantization (support) version TFLite conversion saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1S9GJYMnZUN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "8120d7a8-9df5-423e-c0f9-2cc8d4a47c96"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
        "\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "\n",
        "qtflite_model = converter.convert()\n",
        "\n",
        "qtflite_model_file = 'test_supportq.tflite'\n",
        "f = open(tflite_model_file, 'wb')\n",
        "f.write(tflite_model)\n",
        "f.close()\n",
        "print(\"quantization (support) version TFLite conversion saved\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-f991b26a4f82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZE_FOR_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mqtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mqtflite_model_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test_supportq.tflite'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    670\u001b[0m     return super(TFLiteSavedModelConverterV2,\n\u001b[1;32m    671\u001b[0m                  \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                                output_tensors)\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[1;32m    550\u001b[0m                                   self.representative_dataset, graph_def)\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inference_input_output_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquant_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_unknown_shapes_allowed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_validate_inference_input_output_types\u001b[0;34m(self, quant_mode)\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_input_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdefault_types\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_output_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdefault_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m       raise ValueError(\"The inference_input_type and inference_output_type \"\n\u001b[0m\u001b[1;32m    528\u001b[0m                        \"must be tf.float32.\")\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The inference_input_type and inference_output_type must be tf.float32."
          ]
        }
      ]
    }
  ]
}